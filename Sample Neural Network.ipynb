{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15dc78a8-f5dc-45b1-abfd-fcb65807551e",
   "metadata": {},
   "source": [
    "# Sample Neural Network\n",
    "\n",
    "Enrico Borriello - Didactic material - CAS 522 Dynamical Systems\n",
    "\n",
    "---\n",
    "\n",
    "In this example, we builds and trains a simple feedforward neural network using **TensorFlow** and **Keras** to classify handwritten digits from the *MNIST* dataset. It includes data loading, normalization, flattening, model definition, compilation, training, and evaluation. Finally, it prints the test accuracy to show how well the model performs on unseen data.\n",
    "\n",
    "In a later example, we will see how this simple idea can be adapted and built upon to handle problems involving dynamical systems, once we modify our input representation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f958920f-5e02-4382-95ac-360ee8d43d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6205678-b02f-404d-9dea-b53f1d5d26f5",
   "metadata": {},
   "source": [
    "**TensorFlow** is an open-source framework for building and training machine learning models. **Keras** (bundled inside TensorFlow) provides a high-level, user-friendly API for defining and training neural networks. The **layers** module contains building blocks (such as `Dense`, `Conv2D`, and `Dropout`) that are used to construct neural network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b532210b-3852-43d6-b791-5e5f44c40f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f241566-d92f-4de5-a492-25085436d5e1",
   "metadata": {},
   "source": [
    "This line loads the MNIST dataset, a collection of 70,000 grayscale images of handwritten digits (0–9). The dataset is automatically downloaded through Keras and split into two parts: a training set (`x_train`, `y_train`) used to teach the model, and a test set (`x_test`, `y_test`) used to evaluate its performance. Each image is 28×28 pixels, and the labels represent the digit shown in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172c68b6-d4c6-43a9-a5a1-c9dc4fd1684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values (0–255 -> 0–1)\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40612f80-40ef-444a-a08a-76f24f495250",
   "metadata": {},
   "source": [
    "This step normalizes the image data so that pixel values fall between 0 and 1 instead of 0 to 255. Converting `x_train` and `x_test` to type `float32` and dividing by 255.0 ensures the data is scaled consistently, which helps the neural network train more efficiently and improves numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac6520e-c0e4-442c-b660-516779aa5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten 28x28 images into 784-dim vectors\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59314a17-f532-42e0-a06e-1f60efb7788d",
   "metadata": {},
   "source": [
    "This step reshapes each image from a 2D array of size 28 × 28 into a 1D vector of length 784. Flattening the images (`x_train` and `x_test`) allows them to be used as inputs to a fully connected neural network, which expects feature vectors rather than 2D grids. The `-1` tells NumPy to automatically infer the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a521b74-6c16-403a-9ff6-bb5725c3b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build a simple feedforward neural network\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation=\"relu\", input_shape=(784,)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")  # 10 classes for digits 0–9\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364bcdc-aeb8-426f-8afa-b24e936edae8",
   "metadata": {},
   "source": [
    "This block defines a simple feedforward neural network using the Keras `Sequential` API. The model is built as a sequence of fully connected (`Dense`) layers:\n",
    "\n",
    "- The first layer has 128 units with the ReLU activation function and takes an input vector of length 784 (the flattened image).\n",
    "- The second layer has 64 units with ReLU activation to capture more complex features.\n",
    "- The final layer has 10 units with a softmax activation, producing probabilities for each of the 10 digit classes (0–9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250da20d-1801-430c-823a-3ce4db7b86c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c29b009-91c7-455a-917e-83a6fcb9f3f0",
   "metadata": {},
   "source": [
    "This step configures the model for training. The **Adam** optimizer is chosen for efficient gradient-based optimization. The loss function `sparse_categorical_crossentropy` is used because the labels are integers representing classes (0–9), not one-hot encoded vectors. The model is also set to track accuracy as a performance metric during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273e86c0-dc18-4013-8f3a-6b387a02cc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.4300 - val_accuracy: 0.9652 - val_loss: 0.1175\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.1148 - val_accuracy: 0.9742 - val_loss: 0.0905\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0730 - val_accuracy: 0.9723 - val_loss: 0.0906\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0546 - val_accuracy: 0.9750 - val_loss: 0.0892\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0415 - val_accuracy: 0.9768 - val_loss: 0.0849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x134564250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691cbd7-1737-4ab8-985c-7be972eb9fc6",
   "metadata": {},
   "source": [
    "This line trains the neural network on the `x_train` and `y_train` data. The model is trained for 5 epochs (complete passes through the training data) with a `batch_size` of 32, meaning the weights are updated after every 32 samples. `validation_split=0.1` reserves 10% of the training data for validation, allowing the model’s performance to be monitored on unseen data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f90131b-0a77-46b9-9ed8-31930dba4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - 937us/step - accuracy: 0.9757 - loss: 0.0838\n",
      "Test accuracy: 0.9757\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971ee6e-be13-4fcb-a9ac-57984afe25ea",
   "metadata": {},
   "source": [
    "This block evaluates the trained model on the test dataset (`x_test`, `y_test`) to measure its performance on unseen data. The `model.evaluate()` method returns the loss (`test_loss`) and the accuracy (`test_acc`). Setting `verbose=2` provides a concise progress output. Finally, the test accuracy is printed to give a clear measure of how well the model generalizes to new examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b47577-a474-4b03-a9d8-1b9aa6e6bd4f",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b194df1b-354d-476b-83b4-a1a3383305ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Choose an example index\n",
    "index = 42  # change this to view a different image\n",
    "\n",
    "# Get the image and label\n",
    "image = x_test[index].reshape(28, 28)  # reshape back to 28x28 for plotting\n",
    "true_label = y_test[index]\n",
    "\n",
    "# Predict with the model\n",
    "pred_probs = model.predict(x_test[index].reshape(1, 784))  # reshape to match input\n",
    "pred_label = np.argmax(pred_probs)\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"True: {true_label}, Predicted: {pred_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
